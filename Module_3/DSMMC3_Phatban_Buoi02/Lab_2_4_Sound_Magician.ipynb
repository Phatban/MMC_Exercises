{"cells":[{"cell_type":"markdown","metadata":{"id":"CtpmzhmaTg_C"},"source":["# Sound Magician\n","\n","Thời lượng ước tính: **120** phút\n","\n","## Giới thiệu lab\n","Nâng cao! Có thể bạn đã từng xem một bộ phim hoặc chương trình truyền hình mà các điệp viên siêu hạng sử dụng một số kỹ thuật khó tin để nâng cao hình ảnh pixelated hoặc khôi phục một số dữ liệu bị mất. Trong lab này, bạn sẽ thực hiện điều tương tự — lần này mục tiêu của bạn là sử dụng hồi quy tuyến tính để khôi phục hoặc 'điền vào' phần bị xóa hoàn toàn của một tệp âm thanh!\n","\n","Để hoàn thành lab này, bạn sẽ sử dụng FSDD (Free-Spoken-Digits-Dataset), một tập dữ liệu âm thanh do Zohar Jackson tổng hợp lại khi anh ấy nhận thấy không có nhiều âm thanh được làm sạch (không có khoảng trống, độ dài tương đương, cùng bitrate, cùng tỷ lệ mẫu trên giây, ...) thư viện âm thanh sẵn sàng cho machine learning."]},{"cell_type":"code","execution_count":62,"metadata":{"id":"UPQa1SVTTg_G"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.utils.validation import check_random_state\n","import scipy.io.wavfile as wavfile"]},{"cell_type":"markdown","metadata":{"id":"FIJAy5U0Tg_T"},"source":["### Về Âm thanh"]},{"cell_type":"markdown","metadata":{"id":"y9lY3g5oTg_U"},"source":["Mẫu là các quan sát. Mỗi tệp âm thanh sẽ là một mẫu duy nhất trong tập dữ liệu.\n","\n","Tìm thêm thông tin về [Mẫu âm thanh tại đây] (https://en.wikipedia.org/wiki/Sampling_(signal_processing)).\n","\n","Mỗi tệp .wav thực sự chỉ là một loạt các mẫu số, được lấy mẫu từ tín hiệu analog. Sampling (Lấy mẫu) là một kiểu rời rạc. Khi chúng ta đề cập đến các 'sample (mẫu)', tức là các quan sát. Khi đề cập đến 'audio sample', chúng ta muốn nói đến \"feature (thuộc tính)\" thực sự của tệp âm thanh.\n","\n","Mục tiêu của lab này là sử dụng hồi quy tuyến tính, đa mục tiêu để tạo ra bằng phép ngoại suy phần bị thiếu của tệp âm thanh thử nghiệm.\n","\n","Mỗi một thuộc tính audio_sample sẽ là đầu ra của một phương trình, là một hàm của phần được cung cấp của audio_samples:\n","\n","    missing_samples = f(provided_samples)\n","\n","Bạn có thể thử với lượng âm thanh bạn muốn cắt và để máy tính tạo ra bằng tham số Provided_Portion."]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"ayulRqRrTg_W"},"source":["Hãy sử dụng cái này. Đây là lượng tệp âm thanh sẽ được cung cấp, tính bằng phần trăm. Phần trăm còn lại của tệp sẽ được tạo thông qua phép ngoại suy tuyến tính."]},{"cell_type":"code","execution_count":63,"metadata":{"id":"i7chXL5DTg_X"},"outputs":[],"source":["Provided_Portion = 0.25"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"CvGpdC1RTg_d"},"source":["## 1. Chuẩn bị dữ liệu"]},{"cell_type":"markdown","metadata":{"id":"KMngCekmTg_f"},"source":["Bắt đầu bằng cách tạo một list Python thông thường là `zero`:"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"14JWhfK6Tg_g"},"outputs":[],"source":["# Nhập code của bạn ở đây\n","zero = []"]},{"cell_type":"markdown","metadata":{"id":"lJTKO612Tg_m"},"source":["Lặp qua tập dữ liệu và tải lên tất cả 50 tệp `0_jackson*.wav` bằng phương thức `wavfile.read()`: https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.io.wavfile.read.html từ thư mục [data](https://drive.google.com/drive/folders/1UDAvuRfXzcOcpI84neQAmAeffIrJKKBi?usp=sharing).\n","\n","Hãy cẩn thận! `.read()` trả về một tuple và bạn chỉ quan tâm đến dữ liệu âm thanh chứ không phải sample_rate tại thời điểm này. Bên trong vòng lặp for, chỉ cần nối dữ liệu âm thanh đã tải vào list Python `zero`:"]},{"cell_type":"code","execution_count":65,"metadata":{"id":"DUwnRGm-Tg_n"},"outputs":[],"source":["# Nhập code của bạn ở đây\n","import os\n","\n","for filename in os.listdir('data'):\n","    if filename.startswith('0_jackson') and filename.endswith('.wav'):\n","        sample_rate, audio_data = wavfile.read(os.path.join('data', filename))\n","        zero.append(audio_data)"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"dzHr1FEzTg_u"},"source":["Hãy dành một chút thời gian để chuyển 0 thành một khung dữ liệu (DataFrame). Khi bạn làm như vậy, hãy đặt `dtype` thành `np.int16`, vì các tệp âm thanh đầu vào là 16 bit cho mỗi mẫu. Nếu bạn không biết cách thực hiện việc này, hãy đọc tài liệu tại đây: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html\n","\n","Tiếc là những đoạn âm thanh này không được chuẩn hóa độ dài nên chúng ta sẽ phải chia nhỏ chúng để tất cả có cùng độ dài. Vì Pandas sẽ chèn các NAN tại bất kỳ vị trí nào để tạo thành mảng [n_observed_samples, n_audio_samples] hình chữ nhật hoàn hảo nên hãy thực hiện một `dropna` trên trục Y ở đây. Sau đó, chuyển đổi 1 trở lại thành NDArray bằng `yourarrayname.values`:"]},{"cell_type":"code","execution_count":66,"metadata":{"id":"HzG76oSaTg_v"},"outputs":[],"source":["## Nhập code của bạn ở đây\n","import pandas as pd\n","import numpy as np\n","\n","zero = pd.DataFrame(zero)\n","zero = zero.fillna(0)\n","zero = zero.replace([np.inf, -np.inf], 0)\n","zero = zero.astype(np.int16)\n","zero = zero.dropna(axis=1).values"]},{"cell_type":"markdown","metadata":{"id":"litpLIunTg_2"},"source":["Điều quan trọng là phải biết  (bao nhiêu mẫu audio_samples) độ dài dữ liệu hiện có.\n","\n","`zero` hiện có shape giống như` [n_samples, n_audio_samples] `, vì vậy hãy lấy số lượng` n_audio_samples` và lưu trữ nó trong biến `n_audio_samples`:"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"BJT-HkwsTg_4"},"outputs":[{"data":{"text/plain":["6273"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["# Nhập code của bạn ở đây\n","n_audio_samples = zero.shape[1]\n","n_audio_samples"]},{"cell_type":"markdown","metadata":{"id":"X_o9dFonajuZ"},"source":["## 2. Huấn luyện mô hình"]},{"cell_type":"markdown","metadata":{"id":"OKs-DpagTg__"},"source":["Tạo mô hình hồi quy tuyến tính của bạn tại đây và lưu trữ nó trong biến `model`. Đừng vội huấn luyện hoặc làm bất cứ điều gì khác với nó:"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"YYi87mhQThAA"},"outputs":[],"source":["# Nhập code của bạn ở đây\n","from sklearn.linear_model import LinearRegression\n","model = LinearRegression()"]},{"cell_type":"markdown","metadata":{"id":"Q1sUz2UwThAF"},"source":["Có 50 bản ghi mỗi clip. Bạn chỉ muốn lấy ngẫu nhiên một trong số chúng ra và cái đó sẽ KHÔNG được sử dụng trong quá trình huấn luyện mô hình. Nói cách khác, tệp mà chúng ta sẽ kiểm tra/chấm điểm sẽ là một mẫu không nhìn thấy, độc lập với phần còn lại của training set:"]},{"cell_type":"code","execution_count":69,"metadata":{"id":"8ewvSE_1ThAG"},"outputs":[],"source":["# Hãy để nguyên dòng này cho đến khi bạn đã submit bài Lab của mình:\n","rng = check_random_state(7)\n","\n","random_idx = rng.randint(zero.shape[0])\n","test  = zero[random_idx]\n","train = np.delete(zero, [random_idx], axis=0)"]},{"cell_type":"markdown","metadata":{"id":"l-ft2fTvThAO"},"source":["In ra shape của `train` và `test`.\n","\n","`train` sẽ có dạng:`[n_samples, n_audio_samples]`, trong đó `n_audio_samples` là 'features' (thuộc tính) của tệp âm thanh\n","\n","`test` sẽ có dạng `[n_audio_features]`, vì nó là mẫu duy nhất (tệp âm thanh, ví dụ: quan sát)."]},{"cell_type":"code","execution_count":70,"metadata":{"id":"Soc8ciucThAP"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train shape: (49, 6273)\n","Test shape: (6273,)\n"]}],"source":["# Nhập code của bạn ở đây\n","print(\"Train shape:\", train.shape)\n","print(\"Test shape:\", test.shape)"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"xIoIIWN-ThAb"},"source":["Dữ liệu thử nghiệm sẽ có hai phần, `X_test` và` y_test`.\n","\n","`X_test` là phần đầu tiên của tệp âm thanh thử nghiệm mà chúng ta sẽ cung cấp cho máy tính làm input.\n","\n","`y_test`,\"nhãn\" sẽ là phần còn lại của tệp âm thanh. Như vậy, máy tính sẽ sử dụng hồi quy tuyến tính để lấy ra phần bị thiếu của tệp âm thanh dựa trên dữ liệu huấn luyện mà nó nhận được!\n","\n","Hãy lưu clip `test` ban đầu, clip mà bạn sắp xóa một nửa vào thư mục hiện tại để bạn có thể so sánh nó với clip 'đã vá' sau khi tạo. Bạn hẳn đã có `sample_rate` khi tải lên các tệp .wav: "]},{"cell_type":"code","execution_count":71,"metadata":{"id":"zxPW90H9ThAd"},"outputs":[],"source":["wavfile.write('Original Test Clip.wav', sample_rate, test)"]},{"cell_type":"markdown","metadata":{"id":"rIkmkMqNThAk"},"source":["Chuẩn bị dữ liệu TEST bằng cách tạo lát `X_test`. Nó phải có các thuộc tính mẫu âm thanh `Provided_Portion` * `n_audio_samples`, được lấy từ tệp âm thanh thử nghiệm, hiện được lưu trữ trong biến `test`. Nói cách khác, lấy các thuộc tính âm thanh `Provided_Portion` * `n_audio_samples` ĐẦU TIÊN từ `test` và lưu trữ nó trong` X_test`. Điều này sẽ được thực hiện bằng cách sử dụng lập chỉ mục:"]},{"cell_type":"code","execution_count":72,"metadata":{"id":"IECZK7pGThAl"},"outputs":[],"source":["# Nhập code của bạn ở đây\n","X_test = test[:int(Provided_Portion * n_audio_samples)]"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"Pt50X7z-ThAw"},"source":["Nếu các thuộc tính `Provided_Portion` * `n_audio_samples` đầu tiên được lưu trữ trong `X_test`, thì chúng ta cũng cần lấy các thuộc tính âm thanh _còn lại_ và lưu trữ chúng trong` y_test`. Với các thuộc tính còn lại được lưu trữ trong đó, chúng ta sẽ có thể R ^ 2 \"chấm điểm\" thuật toán đã làm tốt như thế nào trong việc hoàn thành tệp âm thanh."]},{"cell_type":"code","execution_count":73,"metadata":{"id":"AbbmCXo9ThAx"},"outputs":[],"source":["# Nhập code của bạn ở đây\n","y_test = test[int(Provided_Portion * n_audio_samples):]"]},{"cell_type":"markdown","metadata":{"id":"W0DXxAEhThBA"},"source":["Lặp lại quy trình tương tự cho `X_train`, `y_train`. Sự khác biệt duy nhất là:\n","\n","1. Bạn sẽ nhận được dữ liệu âm thanh từ `train` thay vì từ `test`\n","2. Bạn có nhớ shape của `train` mà bạn đã in ra trước đó không? Bạn muốn thực hiện việc cắt này nhưng đối với TẤT CẢ các mẫu (quan sát). Đối với mỗ quan sát, bạn muốn chia các thuộc tính âm thanh `Provided_Portion` * `n_audio_samples` đầu tiên thành `X_train`, và phần còn lại chuyển vào `y_train`. Có thể thực hiện tất cả những điều này bằng lập chỉ mục thông thường ở 2 dòng code:"]},{"cell_type":"code","execution_count":74,"metadata":{"id":"8CgSV4-IThBC"},"outputs":[],"source":["# Nhập code của bạn ở đây\n","X_train = train[:, :int(Provided_Portion * n_audio_samples)]\n","y_train = train[:, int(Provided_Portion * n_audio_samples):]"]},{"cell_type":"markdown","metadata":{"id":"gVZG3AQwThBN"},"source":["SciKit-Learn sẽ 'tức giận' nếu bạn không cung cấp dữ liệu huấn luyện dưới dạng khung dữ liệu 2D có shape `[n_samples, n_features]`.\n","\n","Vì vậy, nếu bạn chỉ có một MẪU, chẳng hạn như trường hợp của chúng ta với `X_test` và `y_test` thì bằng cách gọi `.reshape(1, -1)`, bạn có thể biến `[n_features]` thành `[1, n_features] `để đáp ứng SciKit-Learn.\n","\n","Mặt khác, nếu bạn chỉ có một THUỘC TÍNH, bạn có thể gọi `.reshape (-1, 1)` trên dữ liệu của mình để biến `[n_samples]` thành `[n_samples, 1]`.\n","\n","Định hình lại X_test và y_test thành [1, n_features]:"]},{"cell_type":"code","execution_count":75,"metadata":{"id":"ovi6Z4vAThBO"},"outputs":[],"source":["# Nhập code của bạn ở đây\n","X_test = X_test.reshape(1, -1)\n","y_test = y_test.reshape(1, -1)"]},{"cell_type":"markdown","metadata":{"id":"pveoa3OSThBV"},"source":["Điều chỉnh mô hình của bạn bằng cách sử dụng dữ liệu huấn luyện và nhãn:"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"aWrzESmWThBW"},"outputs":[{"data":{"text/html":["<style>#sk-container-id-3 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: black;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-3 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-3 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-3 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-3 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-3 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-3 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-3 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-3 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-3 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-3 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-3 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-3 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-3 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-3 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-3 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: block;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","}\n","\n","#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"▸\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-3 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-3 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-3 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"▾\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-3 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-3 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-3 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-3 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-3 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-3 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-3 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 1ex;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `<a>` HTML tag */\n","\n","#sk-container-id-3 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-3 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-3 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"],"text/plain":["LinearRegression()"]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["# Nhập code của bạn ở đây\n","model.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"beK3QB4Ha1SW"},"source":["## 3. Đánh giá mô hình"]},{"cell_type":"markdown","metadata":{"id":"xkUDZHtkThBd"},"source":["Sử dụng mô hình để dự đoán `label` của `X_test`. Lưu trữ dự đoán kết quả trong biến `y_test_prediction`:"]},{"cell_type":"code","execution_count":77,"metadata":{"id":"ShxFfA0IThBe"},"outputs":[],"source":["# Nhập code của bạn ở đây\n","y_test_prediction = model.predict(X_test)"]},{"cell_type":"markdown","metadata":{"id":"9oSFOALZThBi"},"source":["SciKit-Learn sẽ sử dụng float64 để tạo các dự đoán của bạn, vì vậy hãy đưa các giá trị đó trở lại int16, đó là những gì tệp .wav cần:"]},{"cell_type":"code","execution_count":78,"metadata":{"id":"wbnClMVCThBj"},"outputs":[],"source":["y_test_prediction = y_test_prediction.astype(dtype=np.int16)"]},{"cell_type":"markdown","metadata":{"id":"oYqV-K4IThBo"},"source":["Chấm điểm dự đoán của bạn sẽ hoạt động tốt như thế nào bằng cách truyền dữ liệu và nhãn thử nghiệm `y_test`:"]},{"cell_type":"code","execution_count":79,"metadata":{"id":"qF-R89wLThBp"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n","  warnings.warn(msg, UndefinedMetricWarning)\n"]}],"source":["# Nhập code của bạn ở đây\n","score = model.score(X_test, y_test)"]},{"cell_type":"code","execution_count":80,"metadata":{"id":"uAwVxcTOThBu"},"outputs":[{"name":"stdout","output_type":"stream","text":["Extrapolation R^2 Score:  nan\n"]}],"source":["print(\"Extrapolation R^2 Score: \", score)"]},{"cell_type":"markdown","metadata":{"id":"Qxlg7hWRThB1"},"source":["Hãy lấy phần `Provided_Portion` đầu tiên của clip thử nghiệm, phần mà bạn đã đưa vào mô hình hồi quy tuyến tính. Sau đó, kết hợp điều đó với thứ mà mô hình dự đoán đã tạo cho bạn và sau đó lưu đoạn âm thanh đã hoàn thành:"]},{"cell_type":"code","execution_count":81,"metadata":{"id":"co0UKuZ0ThB2"},"outputs":[],"source":["completed_clip = np.hstack((X_test, y_test_prediction))\n","wavfile.write('Extrapolated Clip.wav', sample_rate, completed_clip[0])"]}],"metadata":{"anaconda-cloud":{},"colab":{"collapsed_sections":[],"name":"Lab_2_4_Sound_Magician.ipynb","provenance":[]},"kernelspec":{"display_name":"Python [default]","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"toc":{"colors":{"hover_highlight":"#DAA520","running_highlight":"#FF0000","selected_highlight":"#FFD700"},"moveMenuLeft":true,"nav_menu":{"height":"58px","width":"252px"},"navigate_menu":true,"number_sections":true,"sideBar":true,"threshold":4,"toc_cell":false,"toc_section_display":"block","toc_window_display":false,"widenNotebook":false}},"nbformat":4,"nbformat_minor":0}
